{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc38325",
   "metadata": {},
   "source": [
    "# Understanding the concept :-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e787bd",
   "metadata": {},
   "source": [
    "## 1. **torch.pad()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723109a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256, 258])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn.functional import pad as Padding \n",
    "\n",
    "tensor = torch.randn(2, 3, 256, 256)\n",
    "\n",
    "# padding last (width) dim by 1 on each side \n",
    "# (1, 1) = (1 + 1)\n",
    "# 256 + (1, 1) => 258\n",
    "pad1 = (1, 1)\n",
    "\n",
    "output = Padding(input=tensor,\n",
    "                pad=pad1,\n",
    "                mode='constant',\n",
    "                value=0)\n",
    "\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b672904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 258, 258])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn.functional import pad as Padding \n",
    "\n",
    "tensor = torch.randn(2, 3, 256, 256)\n",
    "\n",
    "# padding last (width, height) dim by 1 on each side \n",
    "pad1 = (1, 1, 1, 1)\n",
    "\n",
    "output = Padding(input=tensor,\n",
    "                pad=pad1,\n",
    "                mode='constant',\n",
    "                )\n",
    "\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ba7c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 9, 258, 258])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn.functional import pad as Padding \n",
    "\n",
    "tensor = torch.randn(2, 3, 8, 256, 256)\n",
    "\n",
    "# padding last (width, height, frame) dim by 1 on each side \n",
    "pad1 = (1, 1, 1, 1, 1, 0)\n",
    "\n",
    "output = Padding(input=tensor,\n",
    "                pad=pad1,\n",
    "                mode='constant',\n",
    "                )\n",
    "\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f80d09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 10, 258, 258])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn.functional import pad as Padding \n",
    "\n",
    "tensor = torch.randn(2, 3, 8, 256, 256)\n",
    "\n",
    "# padding last (width, height, frame, channels) dim by 1 on each side \n",
    "pad1 = (1, 1, 1, 1, 1, 1, 1, 1)\n",
    "\n",
    "output = Padding(input=tensor,\n",
    "                pad=pad1,\n",
    "                mode='constant',\n",
    "                )\n",
    "\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c433b5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 10, 258, 258])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch.nn.functional import pad as Padding \n",
    "\n",
    "tensor = torch.randn(2, 3, 8, 256, 256)\n",
    "\n",
    "# padding last (width, height, frame, channels, batch_size) dim by 1 on each side \n",
    "pad1 = (1, 1, 1, 1, 1, 1, 1, 1, 1, 0)\n",
    "\n",
    "output = Padding(input=tensor,\n",
    "                pad=pad1,\n",
    "                mode='constant',\n",
    "                )\n",
    "\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae597dd",
   "metadata": {},
   "source": [
    "# 2. torch.AvgPool3d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5dda011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 6, 254, 254])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "avg_pool = nn.AvgPool3d(kernel_size=3,\n",
    "                        stride=1)\n",
    "\n",
    "x = torch.randn(2, 3, 8, 256, 256)\n",
    "\n",
    "\n",
    "# frame =  [D_in + 2 * padding[0] - kernel_size[0] / stride[0]] + 1\n",
    "# height =  [h_in + 2 * padding[1] - kernel_size[1] / stride[1]] + 1\n",
    "# width =  [h_in + 2 * padding[2] - kernel_size[2] / stride[2]] + 1\n",
    "\n",
    "avg_pool = avg_pool(x)\n",
    "avg_pool.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529b39a",
   "metadata": {},
   "source": [
    "**Depth Dimension CALCULATION**: \n",
    "```D_in = 8 \n",
    "padding = [0, 0, 0]\n",
    "kernel_size = [3, 3, 3]\n",
    "stride = [1, 1, 1]\n",
    "\n",
    "frame = D_in + 2 * padding[0] - kernel_size[0] / stride[0]\n",
    "frame = frame + 1 \n",
    "frame```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c249a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 6, 254, 254])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "conv = torch.nn.Conv3d(in_channels=3,\n",
    "                       out_channels=3,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=0)\n",
    "\n",
    "x = torch.randn(2, 3, 8, 256, 256)\n",
    "\n",
    "output = conv(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23364451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the input_channels: >>>>>> 128\n",
      "what is the input_channels: 128 and output_channels: 128\n",
      "what is the input_channels: 128 and output_channels: 256\n",
      "what is the input_channels: 256 and output_channels: 512\n",
      "what is the input_channels: 512 and output_channels: 512\n"
     ]
    }
   ],
   "source": [
    "block_out_channels = (128, 256, 512, 512,)\n",
    "down_block_type = (\"DownBlock\", \"DownBlock\", \"DownBlock\", \"DownBlock\",)\n",
    "\n",
    "output_channels = block_out_channels[0]\n",
    "print(f\"what is the input_channels: >>>>>> {output_channels}\")\n",
    "        # self.down_blocks = nn.ModuleList([])\n",
    "for i, down_block_type in enumerate(down_block_type):\n",
    "        input_channels = output_channels\n",
    "        output_channels = block_out_channels[i]\n",
    "        print(f\"what is the input_channels: {input_channels} and output_channels: {output_channels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150efa25",
   "metadata": {},
   "source": [
    "## 3. super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12790a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256, 256])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "class BaseCNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=3,\n",
    "                              out_channels=3,\n",
    "                              kernel_size=1,\n",
    "                              )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "\n",
    "base_cnn = BaseCNN()\n",
    "x = torch.randn(2, 3, 256, 256)\n",
    "output = base_cnn(x)\n",
    "output.shape    # (2, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492c23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 256, 256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomCNN(BaseCNN):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # the `BaseCNN` class to inherit the method \n",
    "        return super().forward(x)\n",
    "    \n",
    "\n",
    "\n",
    "base_cnn = BaseCNN()\n",
    "x = torch.randn(2, 3, 256, 256)\n",
    "output = base_cnn(x)\n",
    "output.shape    # (2, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e28ebc",
   "metadata": {},
   "source": [
    "# 4. enumerate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54de0e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index : 0 and the name: manish\n",
      "index : 1 and the name: anshu\n",
      "index : 2 and the name: ram\n"
     ]
    }
   ],
   "source": [
    "names = [\"manish\", \"anshu\", \"ram\"]\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    print(f\"index : {i} and the name: {name}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8efafe",
   "metadata": {},
   "source": [
    "## 5. nn.Module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e50fb6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Randomclass' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m random_class \u001b[38;5;241m=\u001b[39m Randomclass(in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     26\u001b[0m                            out_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     28\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m) \u001b[38;5;66;03m# image size \u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m output\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Randomclass' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "\n",
    "class Randomclass:\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=2,\n",
    "                              )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "\n",
    "random_class = Randomclass(in_channels=3,\n",
    "                           out_channels=3)\n",
    "\n",
    "x = torch.randn(2, 3, 256, 256) # image size \n",
    "\n",
    "output = random_class(x)\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca87e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 255, 255])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "\n",
    "class Randomclass(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=2,\n",
    "                              )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        return x \n",
    "    \n",
    "\n",
    "\n",
    "random_class = Randomclass(in_channels=3,\n",
    "                           out_channels=3)\n",
    "\n",
    "x = torch.randn(2, 3, 256, 256) # image size \n",
    "\n",
    "output = random_class(x)\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc604fc8",
   "metadata": {},
   "source": [
    "## 6. stride()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad5c68",
   "metadata": {},
   "source": [
    "i follow this page: https://docs.pytorch.org/docs/stable/generated/torch.nn.Conv3d.html\n",
    "\n",
    "```\n",
    "        import math \n",
    "\n",
    "        depth = 8\n",
    "        stride = 2 \n",
    "        padding = 0 # default\n",
    "        kernel_size = 3 # default\n",
    "        dilation = 1 # default \n",
    "        batch_size = 2\n",
    "\n",
    "        calculate_stride = ((depth + batch_size*padding - dilation * (kernel_size - 1) - 1) + 1) / stride\n",
    "        calculate_stride\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6862422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 3, 254, 254])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "stride = (2, 1, 1)\n",
    "\n",
    "\n",
    "conv = nn.Conv3d(in_channels=128,\n",
    "                 out_channels=128,\n",
    "                 kernel_size=3,\n",
    "                 stride=stride)\n",
    "\n",
    "x = torch.randn(2, 128, 8, 256, 256)\n",
    "\n",
    "output = conv(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b436eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 8, 128, 128])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "stride = (1, 2, 2)\n",
    "\n",
    "\n",
    "conv = nn.Conv3d(in_channels=128,\n",
    "                 out_channels=128,\n",
    "                 kernel_size=3,\n",
    "                 stride=stride,\n",
    "                 padding=1) # this padding are applied in forward function \n",
    "\n",
    "x = torch.randn(2, 128, 8, 256, 256)\n",
    "\n",
    "output = conv(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e8e70",
   "metadata": {},
   "source": [
    "## 7. loop zip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaee7fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latter: a and number: 1\n",
      "latter: b and number: 2\n",
      "latter: c and number: 3\n"
     ]
    }
   ],
   "source": [
    "list1 = ['a', 'b', 'c']\n",
    "list2 = [1, 2, 3]\n",
    "\n",
    "for latter, number in zip(list1, list2):\n",
    "    print(f\"latter: {latter} and number: {number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e54954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
